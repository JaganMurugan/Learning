{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNrneKDF2N1SigQD80YZwHG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JaganMurugan/Learning/blob/main/LeNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vAh9Lb2h0tVx"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "uz80wrJ10zjU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "81zK83ke1iXC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "\"\"\"\n",
        "print(time.time())\n",
        "\n",
        "time.sleep(2)\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "time.sleep(2)\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "print(\"Elapsed time:\", end - start)\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDSRJiux83Lc",
        "outputId": "ffe6601e-938c-4476-cee3-bab2569901b8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1746759254.337808\n",
            "Elapsed time: 2.0004985332489014\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Iterable, Tuple\n",
        "from dataclasses import dataclass\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchvision import datasets, transforms"
      ],
      "metadata": {
        "id": "wo_hFFXn9gPI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r4WFwn-pgSA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LeNet5(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # convolution layers\n",
        "    self._body = nn.Sequential(\n",
        "        # First Convolution Layer\n",
        "        # input size = (32, 32), output size = (28, 28)\n",
        "        nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5),\n",
        "        # ReLU activation\n",
        "        nn.ReLU(inplace=True),\n",
        "        # Max pool 2-d\n",
        "        nn.MaxPool2d(kernel_size=2),\n",
        "\n",
        "        # Second Convolution Layer\n",
        "        # input size = (14, 14)\n",
        "        nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.MaxPool2d(kernel_size=2),\n",
        "        # output size = (5, 5)\n",
        "    )\n",
        "\n",
        "    # fully connected layers\n",
        "    self._head = nn.Sequential(\n",
        "        # First fully connected layer\n",
        "        # in_features = total number of weights in last conv layer = 16 * 5* 5\n",
        "        nn.Linear(in_features=16*5*5, out_features=120),\n",
        "\n",
        "        # ReLU activation\n",
        "        nn.ReLU(inplace=True),\n",
        "\n",
        "        # Second fully connected layer\n",
        "        # in_features = output of last linear Layer = 120\n",
        "        nn.Linear(in_features=120, out_features=84),\n",
        "\n",
        "        # ReLU activation\n",
        "        nn.ReLU(inplace=True),\n",
        "\n",
        "        # Third fully connected layer. It is also output layer\n",
        "        # in_features = output of last linear layer = 84\n",
        "        # and out_features =number of classes = 10 (MNIST data 0-9)\n",
        "        nn.Linear(in_features=84, out_features=10)\n",
        "        )\n",
        "\n",
        "  def forward(self, x):\n",
        "    # apply feature extractor\n",
        "    x = self._body(x)\n",
        "    # flatten the output of conv layers\n",
        "    # dimesion should be batch_size * number_of weights_i last_conv layer\n",
        "    x = x.view(x.size([0], -1))\n",
        "    # apply classification head\n",
        "    x = self._head(x)\n",
        "    return x\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "22HkE5_2gfcm"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "XTh7hGK0l1eG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lenet5_model = LeNet5()\n",
        "print(lenet5_model)"
      ],
      "metadata": {
        "id": "B1AIQ6VFJijU",
        "outputId": "23739f3d-7913-45ee-8611-016ed5a3d86e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LeNet5(\n",
            "  (_body): Sequential(\n",
            "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (_head): Sequential(\n",
            "    (0): Linear(in_features=400, out_features=120, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Linear(in_features=120, out_features=84, bias=True)\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Linear(in_features=84, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "train_test_transforms = transforms.Compose([\n",
        "    # Resize to 32X32\n",
        "    transforms.Resize((32, 32)),\n",
        "    # this re-scales image tensor values between 0-1. image_tensor /= 255\n",
        "    transforms.ToTensor(),\n",
        "    # subtract mean (0.1307) and divide by variance (0.3081)\n",
        "    transforms.Normalize((0.1307,), (0.3081))\n",
        "])\n",
        "\"\"\"\n",
        "\n",
        "def get_data(batch_size, data_root='data', num_workers=1):\n",
        "\n",
        "  train_test_tranforms = transforms.Compose([\n",
        "      transforms.Resize(32, 32),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize((0.1307, ), (0.3081, ))\n",
        "  ])\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(\n",
        "      datasets.MNIST(root=data_root, train=True, download=False, transform=train_test_transforms),\n",
        "      batch_size=batch_size,\n",
        "      shuffle=True,\n",
        "      num_workers=num_workers\n",
        "  )\n",
        "\n",
        "  test_loader = torch.utils.data.DataLoader(\n",
        "      datasets.MNIST(root=data_root, train=False, download=False,transform=train_test_transforms),\n",
        "      batch_size=batch_size,\n",
        "      shuffle=False,\n",
        "      num_workers=num_workers\n",
        "  )\n",
        "\n",
        "  return train_loader, test_loader\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "ZDfmpWDnJzd7"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class SystemConfiguration:\n",
        "  '''\n",
        "  Describes the common system setting needed for reproducible training\n",
        "  '''\n",
        "\n",
        "  seed: int = 42 #seed number to set the state of all random generators\n",
        "  cudn_benchmark_enabled: bool = True # enable CuDNN benchmark for the sake of performance\n",
        "  cudnn_deterministic: bool = True # make cudnn deterministic (reproducible training)"
      ],
      "metadata": {
        "id": "k19VZOl0d46o"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r4lI3GAYg8wf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}