{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JaganMurugan/Learning/blob/main/LeNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vAh9Lb2h0tVx"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9kJ8eEOVEVot"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tWHZAO9cnjwe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uz80wrJ10zjU"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81zK83ke1iXC"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "rDSRJiux83Lc",
        "outputId": "9574bb82-a688-46ab-a06b-4799d6c247dd"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nprint(time.time())\\n\\ntime.sleep(2)\\n\\nstart = time.time()\\n\\ntime.sleep(2)\\n\\nend = time.time()\\n\\nprint(\"Elapsed time:\", end - start)\\n'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "\"\"\"\n",
        "print(time.time())\n",
        "\n",
        "time.sleep(2)\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "time.sleep(2)\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "print(\"Elapsed time:\", end - start)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wo_hFFXn9gPI"
      },
      "outputs": [],
      "source": [
        "from typing import Iterable, Tuple\n",
        "from dataclasses import dataclass\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4WFwn-pgSA0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22HkE5_2gfcm"
      },
      "outputs": [],
      "source": [
        "class LeNet5(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self._body = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.MaxPool2d(kernel_size=2),\n",
        "\n",
        "        nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.MaxPool2d(kernel_size=2)\n",
        "    )\n",
        "\n",
        "    self._head = nn.Sequential(\n",
        "        nn.Linear(in_features=16*5*5, out_features=120),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Linear(in_features=120, out_features=84),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Linear(in_features=84, out_features=10)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self._body(x)\n",
        "    x = x.view(x.size()[0], -1)\n",
        "    x = self._head(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyuxD2Q0BgsH",
        "outputId": "6eec7d9c-efd7-4c58-9467-527456ba17df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LeNet5(\n",
            "  (_body): Sequential(\n",
            "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (_head): Sequential(\n",
            "    (0): Linear(in_features=400, out_features=120, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Linear(in_features=120, out_features=84, bias=True)\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Linear(in_features=84, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "lenet = LeNet5()\n",
        "print(lenet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJbvklSPB0tt"
      },
      "outputs": [],
      "source": [
        "def get_data(batch_size, data_root='data',num_workers=1):\n",
        "\n",
        "  train_test_transforms = transforms.Compose([\n",
        "      transforms.Resize(32, 32),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize((0.1307), (0.3081))\n",
        "  ])\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(\n",
        "      datasets.MNIST(root=data_root, train=True, download=False, transform=train_test_transforms),\n",
        "      batch_size=batch_size,\n",
        "      shuffle=True,\n",
        "      num_workers=num_workers\n",
        "  )\n",
        "\n",
        "  test_loader = torch.utils.data.DataLoader(\n",
        "      datasets.MNIST(root=data_root, train=False, download=False, transform=train_test_transforms),\n",
        "      batch_size=batch_size,\n",
        "      shuffle=True,\n",
        "      num_workers=num_workers\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjFN7NRtDmgP"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class SystemConfiguration:\n",
        "  seed: int = 42\n",
        "  cudnn_benchmark_enabled: bool = True,\n",
        "  cudnn_determinisitic: bool = True\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZjaj8cuEUMs"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class TrainingConfiguration:\n",
        "  batch_size: int = 32  # amount of data to pass through the network at each forward-backward iteration\n",
        "  epochs_count: int = 20  # number of times the whole dataset will be passed through the network\n",
        "  learning_rate: float = 0.01  # determines the speed of network's weights update\n",
        "  log_interval: int = 100  # how many batches to wait between logging training status\n",
        "  test_interval: int = 1  # how many epochs to wait before another test. Set to 1 to get val loss at each epoch\n",
        "  data_root: str = \"data\"  # folder to save MNIST data (default: data/mnist-data)\n",
        "  num_workers: int = 10  # number of concurrent processes used to prepare data\n",
        "  device: str = 'cuda'  # device to use for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uoNTOtDJnlO-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class NearestNeighbor:\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def train(self, X, y):\n",
        "    self.Xtr = X\n",
        "    self.ytr = y\n",
        "\n",
        "  def predict(self, X):\n",
        "    num_test = X.shape[0]\n",
        "    Ypred = np.zeros(num_test, dtype=self.ytr.dtype)\n",
        "\n",
        "    for i in range(num_test):\n",
        "      distances = np.sum(np.abs(self.Xtr - X[i,:]), axis=1)\n",
        "      min_index = np.argmin(distances)\n",
        "      Ypred[i] = self.ytr[min_index]\n",
        "\n",
        "    return Ypred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UEHrnP5zhWDO"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKe54dz5ziK6"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KSmmc43x5GNF"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train(\n",
        "    train_config: TrainingConfiguration, model: nn.Module, optimizer: torch.optim.Optimizer,\n",
        "    train_loader: torch.utils.data.DataLoader, epoch_idx: int\n",
        ") -> Tuple[float, float]:\n",
        "  model.train()\n",
        "\n",
        "  batch_loss = np.array([])\n",
        "\n",
        "  batch_acc = np.array([])\n",
        "\n",
        "  for batch_idx, (data, target) in enumerate(train_loader):\n",
        "       indx_target = target.clone()\n",
        "\n",
        "       data = data.to(train_config.device)\n",
        "\n",
        "       target = target.to(train_config.device)\n",
        "\n",
        "       optimizer.zero_grad()\n",
        "\n",
        "       output = model(data)\n",
        "\n",
        "       loss = F.cross_entropy(output, target)\n",
        "\n",
        "       loss.backward()\n",
        "\n",
        "       optimizer.step()\n",
        "\n",
        "       batch_loss = np.append(batch_loss, [loss.item()])\n",
        "\n",
        "       prob = F.softmax(output, dim=1)\n",
        "\n",
        "       pred = prob.data.max(dim=1)[1]\n",
        "\n",
        "       correct = pred.cpu().eq(indx_target).sum()\n",
        "\n",
        "       acc = float(correct) / float(len(data))\n",
        "\n",
        "       batch_acc = np.append(batch_acc, [acc])\n",
        "\n",
        "       if batch_idx % train_config.log_interval == 0 and batch_idx > 0:\n",
        "        print(\n",
        "            'Train Epoch: {} [{}/{}] Loss: {:.6f} Acc: {:.4f}',\n",
        "            epoch_idx, batch_idx * len(data), len(train_loader.dataset), loss.item(), acc\n",
        "        )\n",
        "  epoch_loss = batch_loss.mean()\n",
        "  epoch_acc = batch_acc.mean()\n",
        "  return epoch_loss, epoch_acc\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6T8i0B6qOdx"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "loss = F.cross_entropy(torch.tensor([5.0, 6.0, 7.0]), torch.tensor([5.0, 7.0, 7.0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "me2R-tda7_8g",
        "outputId": "00e31dee-8154-410e-b502-e045729eba35"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "24.744510650634766"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loss.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "TudFpzTU8RhF",
        "outputId": "f7a3f561-114e-41b2-8f0d-6d6cad85257f"
      },
      "outputs": [
        {
          "ename": "IndexError",
          "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-3f06536f77a1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   2138\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"softmax\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2139\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2140\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2142\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
          ]
        }
      ],
      "source": [
        "F.softmax(torch.tensor([[5.0, 6.0, 7.0], [5.0, 6.0, 7.0]]), dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SK-_XFvGLful"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RD5uSM5qLi1v"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLnSx8yWEjWp"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ARgbBDDLE4Gu"
      },
      "outputs": [],
      "source": [
        "class NearestNeighbor:\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def train(self, X, y):\n",
        "    \"\"\" X is N x D where each row is an example. Y is 1-dimension of size N\"\"\"\n",
        "    self.Xtr = X\n",
        "    self.ytr = y\n",
        "\n",
        "  def predict(self, X):\n",
        "    num_test = X.shape[0]\n",
        "\n",
        "    Ypred = np.zeros(num_test, dtype = self.ytr.dtype)\n",
        "\n",
        "    for i in range(num_test):\n",
        "      distances = np.sum(np.abs(self.Xtr - X[i,:]), axis = 1)\n",
        "      min_index = np.argmin(distances)\n",
        "      Ypred[i] = self.ytr[min_index]\n",
        "\n",
        "    return Ypred\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VwAfPDHdH67u"
      },
      "outputs": [],
      "source": [
        "def validate(\n",
        "    train_config: TrainingConfiguration,\n",
        "    model: nn.Module,\n",
        "    test_loader: torch.utils.data.DataLoader,\n",
        ") -> Tuple[float, float]:\n",
        "  model.eval()\n",
        "  test_loss = 0\n",
        "  count_correct_predictions = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "\n",
        "    for data, target in test_loader:\n",
        "      indx_target = target.clone()\n",
        "      data = data.to(train_config.device)\n",
        "\n",
        "      target = target.to(train_config.device)\n",
        "\n",
        "      output = model(data)\n",
        "\n",
        "      test_loss += F.cross_entropy(output, target).item()\n",
        "\n",
        "      prob = F.softmax(output, dim=1)\n",
        "\n",
        "      pred = prob.data.max(dim=1)[1]\n",
        "\n",
        "      count_correct_predictions += pred.cpu().eq(indx_target).sum()\n",
        "\n",
        "    test_loss = test_loss / len(test_loader)\n",
        "\n",
        "    accuracy = 100 * count_correct_predictions /len(test_loader.dataset)\n",
        "\n",
        "    print(\n",
        "        '\\nTest set: Average loss: {:.4f, Accuracy: {}/{} ({:.0f}%)}\\n'.format(\n",
        "            test_loss, count_correct_predictions, len(test_loader.dataset), accuracy\n",
        "        )\n",
        "    )\n",
        "\n",
        "    return test_loss, accuracy/100."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_system(system_config: SystemConfiguration) -> None:\n",
        "    torch.manual_seed(system_config.seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.backends.cudnn_benchmark_enabled = system_config.cudnn_benchmark_enabled\n",
        "        torch.backends.cudnn.deterministic = system_config.cudnn_deterministic"
      ],
      "metadata": {
        "id": "A-ltnDxW6Grz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(system_configuration=SystemConfiguration(), training_configuration=TrainingConfiguration()):\n",
        "\n",
        "    # system configuration\n",
        "    setup_system(system_configuration)\n",
        "\n",
        "    # batch size\n",
        "    batch_size_to_set = training_configuration.batch_size\n",
        "    # num_workers\n",
        "    num_workers_to_set = training_configuration.num_workers\n",
        "    # epochs\n",
        "    epoch_num_to_set = training_configuration.epochs_count\n",
        "\n",
        "    # if GPU is available use training config,\n",
        "    # else lower batch_size, num_workers and epochs count\n",
        "    if torch.cuda.is_available():\n",
        "        device = \"cuda\"\n",
        "    else:\n",
        "        device = \"cpu\"\n",
        "        batch_size_to_set = 16\n",
        "        num_workers_to_set = 2\n",
        "        epoch_num_to_set = 5\n",
        "\n",
        "    # data loader\n",
        "    train_loader, test_loader = get_data(\n",
        "        batch_size=batch_size_to_set,\n",
        "        data_root=training_configuration.data_root,\n",
        "        num_workers=num_workers_to_set\n",
        "    )\n",
        "\n",
        "    # Update training configuration\n",
        "    training_configuration = TrainingConfiguration(\n",
        "        device=device,\n",
        "        epochs_count=epoch_num_to_set,\n",
        "        batch_size=batch_size_to_set,\n",
        "        num_workers=num_workers_to_set\n",
        "    )\n",
        "\n",
        "    # initiate model\n",
        "    model = LeNet5()\n",
        "\n",
        "    # send model to device (GPU/CPU)\n",
        "    model.to(training_configuration.device)\n",
        "\n",
        "    # optimizer\n",
        "    optimizer = optim.SGD(\n",
        "        model.parameters(),\n",
        "        lr=training_configuration.learning_rate\n",
        "    )\n",
        "\n",
        "    best_loss = torch.tensor(np.inf)\n",
        "\n",
        "    # epoch train/test loss\n",
        "    epoch_train_loss = np.array([])\n",
        "    epoch_test_loss = np.array([])\n",
        "\n",
        "    # epoch train/test accuracy\n",
        "    epoch_train_acc = np.array([])\n",
        "    epoch_test_acc = np.array([])\n",
        "\n",
        "    # training time measurement\n",
        "    t_begin = time.time()\n",
        "    for epoch in range(training_configuration.epochs_count):\n",
        "\n",
        "        train_loss, train_acc = train(training_configuration, model, optimizer, train_loader, epoch)\n",
        "\n",
        "        epoch_train_loss = np.append(epoch_train_loss, [train_loss])\n",
        "\n",
        "        epoch_train_acc = np.append(epoch_train_acc, [train_acc])\n",
        "\n",
        "        elapsed_time = time.time() - t_begin\n",
        "        speed_epoch = elapsed_time / (epoch + 1)\n",
        "        speed_batch = speed_epoch / len(train_loader)\n",
        "        eta = speed_epoch * training_configuration.epochs_count - elapsed_time\n",
        "\n",
        "        print(\n",
        "            \"Elapsed {:.2f}s, {:.2f} s/epoch, {:.2f} s/batch, ets {:.2f}s\".format(\n",
        "                elapsed_time, speed_epoch, speed_batch, eta\n",
        "            )\n",
        "        )\n",
        "\n",
        "        if epoch % training_configuration.test_interval == 0:\n",
        "            current_loss, current_accuracy = validate(training_configuration, model, test_loader)\n",
        "\n",
        "            epoch_test_loss = np.append(epoch_test_loss, [current_loss])\n",
        "\n",
        "            epoch_test_acc = np.append(epoch_test_acc, [current_accuracy])\n",
        "\n",
        "            if current_loss < best_loss:\n",
        "                best_loss = current_loss\n",
        "\n",
        "    print(\"Total time: {:.2f}, Best Loss: {:.3f}\".format(time.time() - t_begin, best_loss))\n",
        "\n",
        "    return model, epoch_train_loss, epoch_train_acc, epoch_test_loss, epoch_test_acc"
      ],
      "metadata": {
        "id": "jehVtpZNUYZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, epoch_train_loss, epoch_train_acc, epoch_test_loss, epoch_test_acc = main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "ohj6Hl005hA4",
        "outputId": "5872ef6f-a805-4033-b3a6-75636d064b84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "32",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-9b2598e7e7b4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_train_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_train_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_test_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_test_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-22-cca483ad2bc3>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(system_configuration, training_configuration)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# data loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     train_loader, test_loader = get_data(\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size_to_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mdata_root\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_configuration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_root\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-7791fcec67d3>\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(batch_size, data_root, num_workers)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   train_test_transforms = transforms.Compose([\n\u001b[0;32m----> 4\u001b[0;31m       \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m       \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m       \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1307\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.3081\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m             \u001b[0minterpolation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_interpolation_modes_from_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36m_interpolation_modes_from_int\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mInterpolationMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLANCZOS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     }\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0minverse_modes_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 32"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass\n",
        "@dataclass\n",
        "class Sample:\n",
        "  x: int = 10\n",
        "  y: int = 11"
      ],
      "metadata": {
        "id": "WycFHStx51pt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = Sample()"
      ],
      "metadata": {
        "id": "XJf5wISlU1jw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hQv3OZZVLic",
        "outputId": "e329d610-c3bc-408d-ab21-2f73b5b1af7a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sample(x=10, y=11)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class samplerepr:\n",
        "  def __init__(self, x, y):\n",
        "    self.x = 10\n",
        "    self.y = 11\n",
        "\n",
        "  def __repr__(self):\n",
        "   return f\"Point: x={self.x}, y={self.y}\""
      ],
      "metadata": {
        "id": "XKbI15JZVOp_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sam = samplerepr(10, 11)\n",
        "sam"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSd6KjUaVjo4",
        "outputId": "c4f6dfe4-b86d-4520-f6a4-c5d99e9fb4fd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Point: x=10, y=11"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gAXKOMWNVmOC"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMTWsRBXjhErB9LFv/vtnST",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}